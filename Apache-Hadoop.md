# Apache Hadoop [Documentation](https://hadoop.apache.org/docs/stable/index.html)

Apache Hadoop ( /həˈduːp/) is a collection [ecosystem] of open-source software utilities that facilitates using a network of many computers to solve problems involving massive amounts of data and computation. It provides a software framework for distributed storage and processing of big data using the MapReduce programming model. All the modules in Hadoop are designed with a fundamental assumption that hardware failures are common occurrences and should be automatically handled by the framework


### [Hadoop ecosystem](https://youtu.be/DCaiZq3aBSc)

[HDFS, YARN, MapReduce], Pig (scripts for MapReducing), Hive (queries), Apache Ambari (visualisation), MESOS (resource negotiator, alt to YARN), Spark (processing: python/Java/Scala), HBase (DB), Storm (real-time streaming), Oozie (job scheduler), ZooKeeper (coordination), Sqoop (data ingestion), Flume (collecting data), Kafka (collecting data)
Query Engines: Apache Drill (SQL query on NoSQLs), Hue (visualize and execute queries), Phoenix, Presto, Zeppelin

OLTP, OLAP?